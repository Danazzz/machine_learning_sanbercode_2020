{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Pekerjaan', 'Jenis Kelamin', 'Status Perkawinan'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0e34e732d39d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pekerjaan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Jenis Kelamin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Status Perkawinan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pekerjaan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Jenis Kelamin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Status Perkawinan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m obj_dict2={\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Pekerjaan', 'Jenis Kelamin', 'Status Perkawinan'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# # Load and preprocess data \n",
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_test=pd.get_dummies(df_test,columns=['Pekerjaan','Jenis Kelamin', 'Status Perkawinan'])\n",
    "df_train=pd.get_dummies(df_test,columns=['Pekerjaan','Jenis Kelamin', 'Status Perkawinan'])\n",
    "\n",
    "obj_dict2={\n",
    "    '?':0,\n",
    "    'Tidak Pernah Bekerja':1,\n",
    "    'Tanpa di Bayar':2,\n",
    "    'Pekerja Bebas Bukan Perusahan':3,\n",
    "    'Pekerja Bebas Perusahaan':4,\n",
    "    'Wiraswasta':5,\n",
    "    'Pemerintah Lokal':6,\n",
    "    'Pemerintah Provinsi':7,\n",
    "    'Pemerintah Negara':8  \n",
    "}\n",
    "df_test['Kelas Pekerja']=df_test['Kelas Pekerja'].replace(obj_dict2)\n",
    "df_train['Kelas Pekerja']=df_train['Kelas Pekerja'].replace(obj_dict2)\n",
    "\n",
    "obj_dict={\n",
    "    'SD':0,\n",
    "    '1st-4th':1,\n",
    "    '5th-6th':2,\n",
    "    'Doktor':15,\n",
    "    '12th':8,\n",
    "    '9th':4,\n",
    "    'Sekolah Professional':11,\n",
    "    '7th-8th':3,\n",
    "    '10th':6,\n",
    "    'D3':10,\n",
    "    '11th':7,\n",
    "    'D4':9,\n",
    "    'Master':14,\n",
    "    'Sarjana':13,\n",
    "    'Pendidikan Tinggi':12,\n",
    "    'SMA':5\n",
    "}\n",
    "df_test['Pendidikan']=df_test['Pendidikan'].replace(obj_dict)\n",
    "df_train['Pendidikan']=df_train['Pendidikan'].replace(obj_dict)\n",
    "\n",
    "obj_dict3={\n",
    "    '<=7jt':0,\n",
    "    '>7jt':1\n",
    "}\n",
    "df['Gaji']=df['Gaji'].replace(obj_dict3)\n",
    "\n",
    "\n",
    "ignored_columns = ['id', 'Gaji']\n",
    "C = df_train.columns\n",
    "\n",
    "# remove constant columns\n",
    "eps = 1e-10\n",
    "dropped_columns = set()\n",
    "print('Identifing low-variance columns...', end=' ')\n",
    "for c in C:\n",
    "    if df_train[c].var() < eps:\n",
    "        # print('.. %-30s: too low variance ... column ignored'%(c))\n",
    "        dropped_columns.add(c)\n",
    "print('done!')\n",
    "C = list(set(C) - dropped_columns - set(ignored_columns))\n",
    "\n",
    "# remove duplicate columns\n",
    "print('Identifying duplicate columns...', end=' ')\n",
    "for i, c1 in enumerate(C):\n",
    "    f1 = df_train[c1].values\n",
    "    for j, c2 in enumerate(C[i+1:]):\n",
    "        f2 = df_train[c2].values\n",
    "        if np.all(f1 == f2):\n",
    "            dropped_columns.add(c2)\n",
    "print('done!')\n",
    "\n",
    "C = list(set(C) - dropped_columns - set(ignored_columns))\n",
    "print('# columns dropped: %d'%(len(dropped_columns)))\n",
    "print('# columns retained: %d'%(len(C)))\n",
    "\n",
    "df_train.drop(dropped_columns, axis=1, inplace=True)\n",
    "df_test.drop(dropped_columns, axis=1, inplace=True)\n",
    "# # Split the Learning Set\n",
    "y_learning = df_train['Gaji'].values\n",
    "X_learning = df_train.drop(['id','Gaji'], axis=1).values\n",
    "\n",
    "id_test = df_test['id']\n",
    "X_test = df_test.drop(['id'], axis=1).values\n",
    "\n",
    "\n",
    "X_fit, X_eval, y_fit, y_eval= train_test_split(\n",
    "    X_learning, y_learning, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "print('# train: %5d (0s: %5d, 1s: %4d)'%(len(y_fit), sum(y_fit==0), sum(y_fit==1)))\n",
    "print('# valid: %5d (0s: %5d, 1s: %4d)'%(len(y_eval), sum(y_eval==0), sum(y_eval==1)))\n",
    "# classifier\n",
    "\n",
    "clf = xgb.XGBClassifier(missing=np.nan, max_depth=6,  objective           = \"binary:logistic\",\n",
    "                        \n",
    "                        n_estimators=620, learning_rate=0.022, \n",
    "                        subsample=0.9, colsample_bytree=0.85, seed=1982)\n",
    "\n",
    "# fitting\n",
    "clf.fit(X_fit, y_fit, early_stopping_rounds=50, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# compute the AUC for the learnt model on training, validation, and local test data.\n",
    "auc_train = roc_auc_score(y_fit, clf.predict_proba(X_fit)[:,1])\n",
    "auc_valid = roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1])\n",
    "\n",
    "print('\\n-----------------------')\n",
    "print('  AUC train: %.5f'%auc_train)\n",
    "print('  AUC valid: %.5f'%auc_valid)\n",
    "print('-----------------------')\n",
    "\n",
    "print('\\nModel parameters...')\n",
    "print(clf.get_params())\n",
    "print('\\n-----------------------\\n')\n",
    "\n",
    "# predicting\n",
    "y_pred= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
